## 存储器概述

### 分类

**按层次分**

* 主存储器：内存，CPU可直接随机对其访问
* 辅助存储器：外存，是主存储器的后援存储器，用来存放当前暂时不用的程序和数据，以及需要永久保存的数据
* 高速缓冲存储器：位于主存和CPU之间，用来存放正在执行的程序段和数据，存取速度可与CPU的速度匹配

**按存取方式**

* 随机存储器(RAM)：又分为SRAM和DRAM
* 只读存储器(ROM)：断电保留内容，随机读写特性，但写入比读取慢得多。
* 串行访问存储器：对存储单元进行读写操作时，需要按其物理位置的先后顺序寻址。

**按信息的可保存性分**

易失性：断电后存储信息消失。

非易失性：断电后信息仍然保持。

### 性能指标

**存储容量**

=存储字数*字长；存储字数表示存储器地址空间的大小，字长表示一次存取操作的数据量。

**单位成本**

每位价格=总成本/总容量

**存储速度**

* 存取时间：从启动一次存储器操作到完成该操作所经历的时间
* 存取周期：存储器进行一次完整的读写操作所需要的全部时间
* 主存带宽：又称数据传输率，每秒从主存进出信息的最大数量

存取时间不等于存储周期，通常存储周期大于存储时间，因为对于任何一种存储器，读写操作后总要有一段恢复内部状态的复原时间。

## 存储器的层次化结构

多级存储系统，用来解决存储器大容量、高速度和低成本3个相互制约的矛盾。

* Cache-主存：解决CPU和主存速度不匹配的问题

* 主存-辅存：解决存储系统的容量问题

辅存要通过主存和CPU交换信息，主存与CPU、Cache、辅存都能交换信息。

主存和Cache之间的数据调动是由硬件自动完成的，对**所有程序员**都透明；主存和辅存之间的数据调动是由硬件和操作系统共同完成的，对**应用程序员**透明。

## 半导体随机存储器

主存由DRAM实现，Cache由SRAM实现，都属于易失性存储器。

### SRAM和DRAM

**SRAM**

把存放一个二进制位的物理器件称为**存储元**，是存储器最基本的构件。地址码相同的多个存储元构成一个**存储单元**。若干存储单元的集合构成**存储体**。

SRAM用双稳态触发器（6个晶体管）来记忆信息，是非破坏性读取。

SRAM存储速度快，但集成度低，功耗较大，一般用来作高速缓存。

**DRAM**

利用存储元电路中栅极电容上的电荷来存储信息，只使用一个晶体管，比SRAM密度高很多。

DRAM采用地址复用技术，地址线是原来的1/2，地址信号分行、列两次传送。

DRAM相对于SRAM来说容易集成、价位低、容量大，但存取速度慢。

DRAM电容上的电荷一般只能维持1-2ms，即使电源不断电，信息也会自动消失。为此必须每隔一定时间刷新，时间一般设为**2ms**，称为**刷新周期**，常用刷新方式有：

* 集中刷新：在一个刷新周期内取一段固定时间依次对存储器的所有行进行逐一再生，在此期间停止对存储器的读写操作，称为**死时间**，又称访存死区。优点是读写操作不受刷新影响，缺点是在集中刷新期间不能进行读写操作。
* 分散刷新：把对每行的刷新分散到各个工作周期中；由此一个存储器的系统工作周期分为两部分：前半部分用于正常读写或保持；后半部分用于刷新。这种方式增加了系统的存取周期，降低了整机速度，优点是没有死区。
* 异步刷新：是前两种方法的结合，既能缩短死时间，又能充分利用最大刷新间隔为2ms的特点。将刷新周期除以行数，得到两次刷新操作之间的时间间隔t，利用逻辑电路每隔时间t产生一次刷新请求，这样可以避免使CPU连续等待过长时间，并且减少刷新次数。

刷新对CPU是透明的，不依赖于外部的访问；DRAM刷新的是行，由芯片内部自行生成行地址。

**存储芯片内部的结构**



### 只读存储器

类型：掩膜式、一次可编程只读、可擦除可编程只读、闪存、固态硬盘。





## 主存储器与CPU的连接

### 连接原理

* 主存通过数据总线、地址总线和控制总线与CPU相连
* 数据总线的位数与工作频率的乘积正比于数据传输率
* 地址总线的位数取决于可寻址的最大内存空间
* 控制总线（读/写）指出本次总线周期的类型以及本次输入/输出操作完成的时刻

### 主存容量的扩展

**位扩展法**

对**字长**进行补充，即增加存储单元的字长，使得**数据位数**与CPU的数据线数相等。

仅仅采用位扩展时，各芯片连接地址线的方式相同，但连接数据线的方式不同，片选信号要连到所有芯片。

eg：利用8片8K*1位的RAM芯片组成8K\*8位的存储器。

**字扩展法**

增加存储器中存储单元（字）的数量，位数不变。字扩展将芯片的地址线、数据线、读写控制线相并联，由片选信号区分各芯片的地址范围。相当于**增加地址线的数量**。

仅采用字扩展时，各芯片连接地址线的方式相同，连接数据线的方式也相同，但某个时刻只需要选中部分芯片，所以通过**片选**芯片或采用**译码器**设计连接到相应的芯片。

**字位同时扩展**

既改变字长，又改变地址数。

### 存储芯片的地址分配和片选

CPU实现**对存储单元的访问**，首先要选择存储芯片，即进行**片选**，然后为选中的芯片依地址码选择相应的存储单元，进行数据的存储，即进行**字选**。片内的字选通常由CPU送出的N条低地址线完成，地址线直接接到所有存储芯片的地址输入端。

片选和字选都相当于通过地址线进行选择。

片选信号的产生分为线选法和译码片选法。

**线选法**

用除了片内寻址外的高位地址线直接分别连接到各个存储芯片的片选端，当某地址线信息位0时，选中与之对应的存储芯片。片选地址线每次寻址时只能有一位有效，不允许同时多位有效。

缺点：地址空间不连续，不能充分利用系统的存储器空间，造成地址资源的浪费。

**译码片选法**

用除片内寻址外的高位地址线通过地址译码器芯片产生片选信号。

## 双端口RAM和多模块存储器

为了提高CPU访问存储器的速度，使用双端口存储器、多模块存储器等技术。

### 双端口RAM

一个存储器有左右两个独立的端口，分别具有两组相互独立的地址线、数据线和读写控制线。允许两个独立的控制器**同时异步地**访问存储单元。

当两个端口的地址不想同时，在两个端口上进行读写操作一定不会发生冲突。

两个端口同时存取存储器的同一地址单元时，会因数据冲突造成数据存储或读取错误。共有以下4中情况：

* 两个端口**不同时**对同一地址单元**存取**数据
* 两个端口**同时**对同一地址单元**读取**数据
* 两个端口**同时**对同一地址单元**写入**数据
* 两个端口**同时**对同一地址单元操作，**一个写入数据，一个读取数据**

前两种不会出现错误，第三种出现写入错误，第四种出现读写错误。

解决方法：置忙信号BUSY位0，由判断逻辑决定暂时关闭一个端口，未被关闭的端口正常访问，被关闭的端口延长一个很短的时间后再访问。

### 多模块存储器

常用的有单体多字存储器和多体低位交叉存储器。

**单体多字存储器**

只有一个存储器，每个存储单元存储m个字，总线宽度也为m个字。一次并行读出m个字，地址必须顺序排列并处于同一存储单元。

该系统在一个存取周期内，从同一地址取出m条指令，然后将指令逐条送至CPU执行，即每个1/m存取周期，CPU向主存取一条指令，这增大了存储器的带宽，提高了工作速度。

缺点：指令和数据必须在内存中连续存放，遇到转移指令，这种方法的效果就不明显了。

**多体并行存储器**

由多体模块组成，每个模块都有相同的容量和读取速度







## 高速缓冲存储器

采用存储体系，通常将存储系统分为“Cache-主存”层次和“主存-辅存”层次。

### 程序访问的局部性原理

包括**时间局部性**和**空间局部性**。时间局部性指的是最近的未来要用到的信息，很可能是**现在正在使用**的信息，因为程序中存在循环。空间局部性是最近的未来要用到的信息，很可能与现在正在使用的信息**在存储空间上是临近**的，因为指令通常是顺序存放、顺序执行的，数据一般也以向量、数组等形式存储在一起。

高速缓冲技术利用程序访问的局部性原理，把程序中正在使用的部分存放在一个高速的、容量较小的Cache中，是CPU的访存操作大多针对Cache进行，从而大大提高程序的执行速度。

### Cache的基本工作原理





### Cache和主存的映射方式

Cache行中的信息是主存中某个块的副本，地址映射是指把主存地址空间映射到Cache地址空间，即把存放的主存中的信息按照某种规则装入Cache。

Cache中的行数比主存块数少得多，主存中只有一部分块的信息可以放在Cache中，因此在Cache中要为每块加一个**标记**，指明其是主存中哪一个块的副本。该标记的内容相当于主存块的编号。另外为了说明Cahce行中的信息是否有效，每个Cache行需要一个**有效位**。

**直接映射**

**主存中的每一块**只能装入Cache中的**唯一位置**。若该位置已有内容，则产生块冲突，原来的块将无条件地被替换出去。这种实现方式较为简单，但不够灵活，即使Cache中的其他许多地址空着也不能占用，这使得直接映射的块冲突概率最高，空间利用率低。

直接映射关系可以定义为：
$$
j=i \ \text{mod} \ 2^c
$$
$j$是Cache的行号，$i$是主存的块号，$2^c$是Cache的总块数；这种映射方式中，主存中的第$0$、$2^c$、$2^{c+1}$....块只能映射到Cache的第0行；主存的第$1$、$2^c+1$、$2^{c+1}+1$....块只能映射到Cache的第1行，以此类推。

从这个定义可以得出，主存块号的**低c位**，正好是其要装入的Cache行号。给每个Cache行设置一个长为$t=m-c$（m为地址长度）的**标记**，当主存某块调入Cache后，就将其块号的高t位设置在对应Cache行的标记中。

CPU访存过程：首先根据访存地址中间的c位找到对应的Cache行，将对应Cache行中的**标记**和主存地址的高t**位进行比较**，若相等且有效位为1，则**命中**，此时根据主存中低位的块内地址，在对应的Cache行中存取信息；若未命中或有效位为0，则CPU从主存中读取出该地址所在的一块信息送到对应的Cache行中，将有效位置1，并将标记设置为地址中的高t位，同时将内容送入CPU。

**全相联映射**

主存中的每一块可以装入Cache中的任何位置，每行的标记用于指出改行取自主存的哪一块，所以CPU访存时需要与所有Cache的行进行比较。

这种方式的优点是比较灵活，Cache块的冲突概率低，空间利用率高，命中率也高；缺点是标记的比较速度较慢，实现成本较高。

**组相联映射**

将Cache空间分为大小相同的组，主存的一个数据块可以装入组内任何一个位置，相当于在**组间采用直接映射**，而**组内采用全相联映射**。

假设每个组有r个Cache行，则称之为r路组相联。

组相联映射关系可以定义为：
$$
j= i \ \text{mod} \ Q
$$
$j$是Cache行的组号，$i$是主存的块号，$Q$是Cache的组数。

路数越大，即每组Cache行的数量越大，发生块冲突的概率越低，但相联比较电路也越复杂。选定适当的适量，可以使组相联映射的成本接近直接映射，而性能上接近全相联映射。

组相联映射的地址结构为：

标记、组号、块内地址

CPU访存过程：首先根据访存地址中的组号找到对应的Cache组；将Cache组中每个行的标记与主存地址的高位标记进行比较，若有一个相等且有限位为1，则访问Cache命中，此时根据主存地址中的块内地址，在对应Cache中存取信息；若都不相等或虽然相等但有效位为0，则不命中，此时CPU从主存中读出该地址所在的信息块并送到Cache对应组的任意一个空闲行，将有效位置1，并设置标记，同时将该地址中的内容送入CPU。

### Cache中主存块的替换算法

采用**全相联和组相联**映射方式时，从主存向Cache传送一个新块，当Cache或Cache组中的空间已被占满时，需要使用替换算法置换Cache行。采用直接映射时，一个给定主存块只能放到唯一的Cache行，当对应Cache行已经有一个主存块存在时，新的主存块会直接把存在的主存块替换掉，无须使用替换算法。





## 虚拟存储器

主存和辅存共同构成了虚拟存储器。



