前5节主要是概念的理解和计算，考选择题。



## 存储器概述

### 分类

**按层次分**

* 主存储器：内存，CPU可直接随机对其访问
* 辅助存储器：外存，是主存储器的后援存储器，用来存放当前暂时不用的程序和数据，以及需要永久保存的数据
* 高速缓冲存储器：位于主存和CPU之间，用来存放正在执行的程序段和数据，存取速度可与CPU的速度匹配

**按存取方式**

* 随机存储器(RAM)：又分为SRAM和DRAM
* 只读存储器(ROM)：断电保留内容，随机读写特性，但写入比读取慢得多。
* 串行访问存储器：对存储单元进行读写操作时，需要**按其物理位置的先后顺序寻址**。(磁带)

**按信息的可保存性分**

易失性：断电后存储信息消失。

非易失性：断电后信息仍然保持。

### 性能指标

**存储容量**

=存储字数*字长；**存储字数**表示存储器**地址空间的大小**，**字长**表示**一次存取操作的数据量**。

**单位成本**

每位价格=总成本/总容量

**存储速度**

* 存取时间：从**启动一次存储器操作到完成该操作**所经历的时间
* 存取周期：存储器进行**一次完整的读写操作**所需要的全部时间
* 主存带宽：又称数据传输率，每秒从主存进出信息的最大数量

存取时间不等于存储周期，通常**存取周期大于存取时间**，因为对于任何一种存储器，读写操作后总要有一段**恢复内部状态的复原时间**。

## 存储器的层次化结构

多级存储系统，用来解决存储器**大容量、高速度和低成本**3个相互制约的矛盾。

* **Cache-主存**：解决CPU和主存速度不匹配的问题

* **主存-辅存**：解决存储系统的容量问题

辅存要通过主存和CPU交换信息，主存与CPU、Cache、辅存都能交换信息。

主存和Cache之间的数据调动是由硬件自动完成的，对**所有程序员**都透明；主存和辅存之间（虚拟内存管理）的数据调动是由**硬件和操作系统**共同完成的，对**应用程序员**透明。

## 半导体随机存储器

主存由DRAM实现，Cache由SRAM实现，都属于易失性存储器。

### SRAM和DRAM

**SRAM**

把存放一个二进制位的物理器件称为**存储元**，是存储器最基本的构件。地址码相同的多个存储元构成一个**存储单元**。若干存储单元的集合构成**存储体**。

SRAM用双稳态触发器（6个晶体管）来记忆信息，是**非破坏性**读取。

SRAM存储速度快，但集成度低，功耗较大，一般用来作高速缓存。

**DRAM**

利用存储元电路中**栅极电容上的电荷**来存储信息，只使用**一个晶体管**，比SRAM密度高很多。

DRAM采用**地址复用技术**，地址线是原来的**1/2**，地址信号**分行、列两次传送**。

DRAM相对于SRAM来说容易集成、价位低、容量大，但存取速度慢。

DRAM电容上的电荷一般只能维持1-2ms，即使电源不断电，信息也会自动消失。为此必须每隔一定时间刷新，时间一般设为**2ms**，称为**刷新周期**，常用刷新方式有：

* **集中**刷新：在一个刷新周期内**取一段固定时间**依次对存储器的所有行进行逐一再生，在此期间停止对存储器的读写操作，称为**死时间**，又称**访存死区**。优点是读写操作不受刷新影响，缺点是在集中刷新期间不能进行读写操作。
* **分散**刷新：把对每行的刷新**分散到各个工作周期**中；由此一个存储器的系统工作周期分为**两部分**：前半部分用于**正常读写或保持**；后半部分用于**刷新**。这种方式增加了系统的存取周期，降低了整机速度，优点是**没有死区**。
* **异步**刷新：是前两种方法的结合，既能缩短死时间，又能充分利用最大刷新间隔为2ms的特点。将刷新周期除以行数，得到两次刷新操作之间的时间间隔t，利用逻辑电路每隔时间t产生一次刷新请求，这样可以避免使CPU连续等待过长时间，并且减少刷新次数。

刷新对CPU是透明的，不依赖于外部的访问；DRAM刷新的是行，由芯片内部自行生成行地址。刷新时不需要片选，即**整个存储器中的所有芯片同时被刷新**。

**存储芯片内部的结构**

* 存储体（存储矩阵）：是存储单元的集合，由行选择线（X）和列选择线（Y） 来选择所访问单元。存储体相同行、列上的单元同时被读出或写入。
* 地址译码器：将地址转换为译码输出线上的高电平，以驱动响应读写电路。
* I/O控制电路：控制被选中单元的读出或写入
* 片选控制信号：选中某个芯片（存储器用多个芯片进行扩展）
* 读/写控制信号

**存储器的读写周期**

* RAM的读周期

读周期时间总是大于等于读出时间。

* RAM的写周期



### 只读存储器ROM

类型：掩膜式、一次可编程只读、可擦除可编程只读、闪存、固态硬盘。

### 主存储器的基本组成

一个个存储0或1的记忆单元构成的存储矩阵是存储器的核心部分。为了存取存储体中的信息，必须对存储单元进行**编址**，现代计算机通常采用**字节编址**方式，此时存储体内的一个地址中有1个字节。

指令执行过程需要访问主存时，CPU首先把访问单元的**地址**送到MAR中，然后通过地址线将主存地址送到主存中的地址寄存器，以便地址译码器进行译码选中相应的单元，同时CPU将**读写控制信号**通过控制线送到主存的读写控制电路。如果是写操作，CPU同时将要写的信息送入MDR中，在读写控制电路的作用下，经数据线将信号写入写中的单元；如果是读操作，那么主存读出选中的单元的内容送到数据线，然后送到MDR中。

**数据线**的宽度与**MDR**的宽度相同，**地址线**的宽度与**MAR**的相同。64位数据线按照字节编址的方式下，最多可以存取8个单元（8字节，字节编址下每个单元1B）的内容。**地址线的位数**决定了主存地址空间的**最大可寻址范围**。

数据线数和地址线数共同反映了存储体容量的大小。

## 主存储器与CPU的连接

### 连接原理

* 主存通过**数据总线、地址总线和控制总线**与CPU相连
* 数据总线的位数与工作频率的乘积正比于数据传输率
* 地址总线的位数取决于可寻址的最大内存空间
* 控制总线（读/写）指出本次总线周期的类型以及本次输入/输出操作完成的时刻

### 主存容量的扩展

**位扩展法**

对**字长**进行补充，即增加存储单元的字长，使得**数据位数**与CPU的数据线数相等。

仅仅采用位扩展时，各芯片连接地址线的方式相同，但**连接数据线的方式不同**，片选信号要连到所有芯片。

eg：利用8片8K*1位的RAM芯片组成8K\*8位的存储器。

**字扩展法**

增加存储器中**存储单元(字)**的数量，位数不变。字扩展将芯片的地址线、数据线、读写控制线相并联，由片选信号区分各芯片的地址范围。相当于**增加地址线的数量**。

仅采用字扩展时，各芯片连接地址线的方式相同，连接数据线的方式也相同，但某个时刻只需要**选中部分芯片**，所以通过**片选**芯片或采用**译码器**设计连接到相应的芯片。

eg：用4片16K*8位的RAM芯片组成64K\*8位的存储器。

**字位同时扩展**

既改变字长，又改变地址数。

### 存储芯片的地址分配和片选

CPU实现**对存储单元的访问**，首先要选择存储芯片，即进行**片选**，然后为选中的芯片依地址码选择相应的存储单元，进行数据的存储，即进行**字选**。片内的字选通常由CPU送出的N条**低地址线**完成，地址线直接接到所有存储芯片的地址输入端。

片选和字选都相当于通过地址线进行选择。

片选信号的产生分为线选法和译码片选法。

**线选法**

用除了片内寻址外的**高位地址**线直接分别连接到各个存储芯片的**片选端**，当某地址线信息为0时，选中与之对应的存储芯片。片选地址线每次寻址时只能有一位有效，不允许同时多位有效。（例如0号芯片地址为1110，1号芯片地址为1101，2号芯片地址为1011，3号芯片地址为0111）

缺点：地址空间不连续，不能充分利用系统的存储器空间，造成地址资源的浪费。

**译码片选法**

用除片内寻址外的高位地址线通过**地址译码器**芯片产生片选信号。

## 双端口RAM和多模块存储器

为了提高CPU访问存储器的速度，使用双端口存储器、多模块存储器等技术。

### 双端口RAM

双通道内存。

一个存储器有左右两个独立的端口，分别具有**两组相互独立的地址线、数据线和读写控制线**。允许两个独立的控制器**同时异步地**访问存储单元。

当两个端口的**地址不相同时**，在两个端口上进行读写操作一定不会发生冲突。

两个端口同时存取存储器的**同一地址单元**时，会因数据冲突造成数据存储或读取错误。共有以下4中情况：

* 两个端口**不同时**对同一地址单元**读写**数据
* 两个端口**同时**对同一地址单元**读取**数据
* 两个端口**同时**对同一地址单元**写入**数据
* 两个端口**同时**对同一地址单元操作，**一个写入数据，一个读取数据**

前两种不会出现错误，第三种出现写入错误，第四种出现读写错误。

解决方法：置忙信号BUSY为0，由判断逻辑决定**暂时关闭一个端口**，未被关闭的端口正常访问，被关闭的端口延长一个很短的时间后再访问。

### 多模块存储器

常用的有单体多字存储器和多体低位交叉存储器。

**单体多字存储器**

只有一个存储器，每个**存储单元**存储**m个字**，**总线宽度**也为**m个字**。**一次并行读出m个字**，地址必须顺序排列并处于同一存储单元。

该系统在一个存取周期内，从同一地址取出m条指令，然后将指令逐条送至CPU执行，即每个1/m存取周期，CPU向主存取一条指令，这增大了存储器的带宽，提高了工作速度。

缺点：指令和数据必须**在内存中连续存放**，遇到转移指令，这种方法的效果就不明显了。

**多体并行存储器**

由多体模块组成，每个模块都有相同的容量和读取速度，各模块都有独立的读写控制电路、地址寄存器和数据寄存器。它们既能并行工作，又能交叉工作。

多体并行存储器分为高位交叉编址（顺序方式）和低位交叉编址（交叉方式）两种：

* 高位交叉编址：高位地址表示**体号**，低位地址为**体内地址**。该方式下总是把低位的体内地址送到由高位体号确定的模块内进行译码。CPU总是按顺序访问存储模块，存储模块不能被并行访问，**不能提高存储器的吞吐率**。
* 低位交叉编址：低位地址为**体号**，高位地址为**体内地址**。每个模块按照**模m交叉编址**，模块号=单元地址%m，假定有m个模块，每个模块有k个单元，则0,m,...,(k-1)m单元位于$M_0$；第1,m+1,...,(k-1)m+1单元位于$M_1$，以此类推。该编址方式下，总把高位的体内地址送到由低位体号确定的模块内进行译码，程序**连续存放在相邻模块**。采用这种编址方式，可以在不改变每个模块存取周期的前提下，采用流水线方式**并行存取**，提高存储器带宽。







## 高速缓冲存储器

采用存储体系，通常将存储系统分为“Cache-主存”层次和“主存-辅存”层次。

### 程序访问的局部性原理

包括**时间局部性**和**空间局部性**。时间局部性指的是最近的未来要用到的信息，很可能是**现在正在使用**的信息，因为程序中存在**循环**。空间局部性是最近的未来要用到的信息，很可能与现在正在使用的信息**在存储空间上是临近**的，因为指令通常是**顺序存放、顺序执行**的，数据一般也以向量、数组等形式存储在一起。

高速缓冲技术利用程序访问的局部性原理，把程序中正在使用的部分存放在一个高速的、容量较小的Cache中，使CPU的访存操作大多针对Cache进行，从而大大提高程序的执行速度。

### Cache的基本工作原理

为了便于Cache和主存的信息交换，**Cache和主存**都被划分为**相等的块**，Cache块又称为**Cache行**，每块由若干字节组成，块的长度称为**块长**(**Cache行长**)。由于Cache的容量远小于主存容量，所以Cache中的块数要远少于主存中的块数，仅保留主存中最活的若干块的副本。

CPU与Cache（或主存）之间的数据交换以**字**为单位，而Cache与主存之间的数据交换以**Cache块**为单位。

CPU欲访问的信息已在Cache中的比率称为Cache的命中率。设一个程序执行期间，Cache的总命中次数为$N_c$，访问主存的总次数为$N_m$，则命中率$H$为：
$$
H=N_c/(N_c+N_m)
$$
命中率越接近于1越好。

### Cache和主存的映射方式

Cache行中的信息是主存中某个块的副本，地址映射是指把主存地址空间映射到Cache地址空间，即把存放的主存中的信息按照某种规则装入Cache。

Cache中的行数比主存块数少得多，主存中只有一部分块的信息可以放在Cache中，因此在Cache中要为每块加一个**标记**，指明其是主存中哪一个块的副本。该标记的内容相当于**主存块的编号**。另外为了说明Cahce行中的**信息是否有效**，每个Cache行需要一个**有效位**。

**直接映射**

**主存中的每一块**只能装入Cache中的**唯一位置**。若该位置已有内容，则产生块冲突，原来的块将无条件地被替换出去。这种实现方式较为简单，但不够灵活，即使Cache中的其他许多地址空着也不能占用，这使得直接映射的块**冲突概率最高，空间利用率低**。

直接映射关系可以定义为（取余运算）：
$$
j=i \ \text{mod} \ 2^c
$$
$j$是Cache的行号，$i$是主存的块号，$2^c$是Cache的总块数；这种映射方式中，主存中的第$0$、$2^c$、$2^{c+1}$....块只能映射到Cache的第0行；主存的第$1$、$2^c+1$、$2^{c+1}+1$....块只能映射到Cache的第1行，以此类推。

从这个定义可以得出，主存块号的**低c位**，正好是其要装入的**Cache行号**。给每个Cache行设置一个长为$t=m-c$（m为地址长度）的**标记**，当主存某块调入Cache后，就将其**块号的高t位**设置在对应Cache行的标记中。

直接映射的地址结构：

* **标记、Cache行、块内地址**

CPU访存过程：首先根据访存地址中的**低c位**找到对应的Cache行，将对应Cache行中的**标记**和主存地址的**高t位进行比较**，若相等且有效位为1，则**命中**，此时根据主存中**低位的块内地址**，在对应的Cache行中存取信息；若未命中或有效位为0，则CPU从主存中读取出该地址所在的一块信息送到对应的Cache行中，将有效位置1，并将标记设置为地址中的高t位，同时将内容送入CPU。

**全相联映射**

主存中的每一块可以装入Cache中的任何位置，**每行的标记**用于指出该行取自**主存的哪一块**，所以CPU访存时需要与所有Cache的行进行比较。

全相联映射的地址结构：

* **标记、块内地址**

这种方式的优点是比较灵活，Cache块的冲突概率低，空间利用率高，命中率也高；缺点是**标记的比较速度较慢，实现成本较高**。

**组相联映射**

将Cache空间分为大小相同的组，主存的一个数据块可以装入组内任何一个位置，相当于在**组间采用直接映射**，而**组内采用全相联映射**。

假设**每个组有r个Cache行**，则称之为**r路**组相联。

组相联映射关系可以定义为：
$$
j= i \ \text{mod} \ Q
$$
$j$是Cache行的**组号**，$i$是**主存的块号**，$Q$是**Cache的组数**。

路数越大，即每组Cache行的数量越大，发生块冲突的概率越低，但相联比较电路也越复杂。选定适当的适量，可以使组相联映射的成本接近直接映射，而性能上接近全相联映射。

组相联映射的地址结构为：

* **标记、组号、块内地址**

CPU访存过程：首先根据访存地址中的组号找到对应的Cache组；将Cache组中每个行的标记与主存地址的高位标记进行比较，若有一个相等且有效位为1，则访问Cache命中，此时根据主存地址中的块内地址，在对应Cache中存取信息；若都不相等或虽然相等但有效位为0，则不命中，此时CPU从主存中读出该地址所在的信息块并送到Cache对应组的任意一个空闲行，将有效位置1，并设置标记，同时将该地址中的内容送入CPU。

**注意关注书上的例题3.4！！！！！！！！！！！！！！**

### Cache中主存块的替换算法

采用**全相联和组相联**映射方式时，从主存向Cache传送一个新块，当Cache或Cache组中的**空间已被占满**时，需要使用替换算法置换Cache行。采用直接映射时，一个给定主存块只能放到唯一的Cache行，当对应Cache行已经有一个主存块存在时，新的主存块会直接把存在的主存块替换掉，无须使用替换算法。

**随机算法(RAND)**

随机地确定替换的Cache块。实现比较简单，未依据程序访问的局部性原理，命中率较低。

**先进先出算法(FIFO)**

选择最早调入的行进行替换。比较容易实现，也未依据程序访问的局部性原理，因为最早进入的主存块可能也是目前经常要使用的。

**近期最少使用算法(LRU)**

依据程序访问的**局部性原理**，选择近期内长久未访问过的Cache行作为替换的行，平均命中率比FIFO高。

LRU算法为每个Cache行设置一个**计数器**，用计数值来记录主存块的使用情况，并根据计数值选择淘汰某个行，计数值的位数与Cache组大小有关，2路时有1位LRU位，4路时有2位LRU位。

计数器的变化规则：

* 命中时，所命中行的计数器清零，比其低的计数器加1，其余不变；
* 未命中且有空闲行时，新装入的行的计数器置0，其余全加1；
* 未命中且无空闲行时，计数值为3的行的信息块被淘汰，新装入的行的计数器置0，其余全加1.

当集中访问的存储区超过Cache组大小时，命中率可能变得很低。

**最不经常使用算法(LFU)**

将一段时间内被访问次数最少的存储行换出，也需要每行设置一个计数器。新行建立后从0开始计数，每访问一次，被访问的行计数器加1，需要替换时比较各行的计数值，将计数值最小的行换出。

### Cache写策略

当对Cache中的内容进行**更新**时，就需选用写操作策略使得**Cache内容和主存内容保持一致**。分两种情况：Cache写命中和Cache写不命中。

**Cache写命中**

写命中时有两种处理方法：

* **全写法**：CPU对Cache写命中时，把数据**同时写入Cache和主存**。当某一块需要替换时，不必把这一块写回主存，用新调入的块直接覆盖即可。这种方法实现简单，能随时保存主存数据的正确性，缺点是增加了访问次数，降低了Cache效率。
  * 写缓冲（Write Buffer）：为了减少全写法写入主存时的时间损耗，在**Cache和主存之间**添加的一个FIFO缓冲队列，可以解决速度不匹配的问题，但若频繁写时，会出现缓冲饱和溢出。
* **写回法**：CPU对Cache写命中时，**只修改Cache的内容，不立即写入主存**，只有当此块**被换出时**才写回主存。这种方法减少了访存次数，但存在**不一致的隐患**。采用这种方法时每个Cache行要设置一个**标志位（脏位）**，反映此块是否被CPU修改过。

**Cache写不命中**

也有两种处理方法：

* **写分配法**：加载主存中的块到Cache中，然后更新这个Cache块，试图利用程序的空间局部性，但缺点是每次不命中都需要从主存中读取一块。
* **非写分配法**：**只写入主存，不进行调块**。
  * 这种方法通常与全写法合用；写分配法通常与写回法合用。
  * 现代计算机通常设立**多级Cache**，一般为L1、L2、L3三级，依次离CPU从近到远，访问速度越来越慢，容量越大。
  * 指令Cache与数据Cache分离一般在L1 Cache，此时通常使用**写分配法与写回法合用**。
  * 一个两级Cache系统中，L1 Cache对L2 Cache使用**全写法**，L2 Cache对主存使用**写回法**；L2 Cache的存在避免了频繁写造成的写缓冲饱和溢出。

## 虚拟存储器

主存和辅存共同构成了虚拟存储器。对于应用程序员来说，虚拟存储器是透明的。虚拟存储器具有**主存的速度和辅存的容量**。

### 基本概念

虚拟存储器将主存或辅存的地址空间同一编址，形成一个庞大的地址空间，在该空间内用户可以自由编程，不必在乎之际的主存容量和程序在主存中存放的位置。

用户编程允许设计的地址称为虚地址或**逻辑地址**，虚地址对应的空间称为虚拟空间；实际主存单元的地址称为实地址。虚地址比实地址大得多。

CPU使用虚地址时，由辅助硬件找出虚地址和实地址之间的对应关系，并判断这个虚地址对应的存储单元是否已经装入主存。若已在主存中，则通过地址变换，CPU可直接访问主存指示的实际单元；若不在主存中，则把包含这个字的一页或一段调入主存后再由CPU访问；若主存已满，则采用替换算法置换主存中的一页或一段。

虚拟存储器由软件（操作系统）和硬件共同实现。

### 页式虚拟存储器

以页为基本单位的存储器。虚拟空间与主存空间都被划分为同样大小的页，主存的页称为**实页**，虚存的页称为**虚页**。

把虚拟地址分为两个字段：**虚页号**和**页内地址**。虚拟地址到物理地址的转换是由页表实现的。

页表是一张存放在主存中的虚页号和实页号（物理块号）的对照表，它记录程序的虚页调入主存时被安排在主存的位置。页表一般长久地保存在主存中。

**页表**

* 有效位（装入位）：用来表示对应页面是否在主存，若为1，则表示该虚拟页已经从外存调入主存，此时页表项存放该页的**物理页号**；若为0，则表示没有调入主存，此时页表项可以存放该页的**磁盘地址**。

* 脏位（修改位）：用来表示页面是否被修改过，虚存机制中采用回写策略，利用脏位可以判断替换时是否需要写回磁盘。
* 引用位（使用位）：用来配合替换策略进行设置，例如FIFO、LRU。

CPU执行指令时，需要先将虚拟地址转换为主存物理地址。**每个进程**都有一个页表基址寄存器，存放该进程的页表首地址，然后根据虚拟地址高位部分的虚拟页号找到对应的页表项。若装入位为1，则取出物理页号，和虚拟地址低位部分进行拼接，形成实际物理地址；若装入位为0，则说明缺页（未调入主存），需要操作系统进行缺页处理。

页式虚拟存储器的优点是页面长度固定、页表简单、调入方便。缺点是页不是逻辑上独立的实体，处理、保护和共享都不如段式虚拟存储器方便。

**快表(TLB)**

依据程序执行的局部性原理，在一段时间内总是经常访问某些页时，若把这些页对应的页表存放在**高速缓冲器**组成的快表（TLB）中，则可以明显地提高效率。相应地把放在主存中的页表称为慢表（Page）。

在地址转换时，首先查找快表，若命中，则无须访问主存中的页表，减少了一次访问主存的次数。

**具有TLB和Cache的多级存储系统**



![](https://raw.githubusercontent.com/eternityqjl/blogGallery/master/%E5%B8%A6TLB%E7%9A%84CPU%E8%AE%BF%E5%AD%98%E8%BF%87%E7%A8%8B.jpg)



### 段式虚拟存储器

段是按照**程序的逻辑结构**划分的，各个段的长度因程序而异。把虚拟地址分为两部分：**段号**和**段内地址**。

虚拟地址到实地址之间的变换是由**段表**来实现的。段表是程序的**逻辑段**和在主存中**存放位置**的对照表。段表的每行记录与某个段对应的段号、装入位、段起点和段长等信息。由于段长度可变，所以段表中要给出各段的起始地址与段的长度。

CPU根据虚拟地址访问时，先根据**段号**和**段表基地址**拼接成对应的段表行，然后根据段表行的装入位判断该段是否已调入主存。已调入主存时，从段表读出该段的起始地址，与段内地址（偏移量）相加，得到对应主存实地址。

### 段页式虚拟存储器

把程序按逻辑结构分段，每段再划分为固定大小的页，主存空间也划分为大小相等的页，程序对主存的点入、调出仍以页为基本单位。这种虚拟存储器中，每个程序对应一个段表，每段对应一个页表，段的长度必须是页长的整数倍，段的起点必须是某一页的起点。

虚地址分为段号、段内页号、页内地址三部分。

详细内容见操作系统相关部分。

### 虚拟存储器与Cache的比较

**相同之处**

都为了提高系统性能；都把数据划分为小信息块，并作为基本的传递单位；都有地址的映射、替换算法、更新策略；都依据程序的局部性原理，应用快速缓存思想，将活跃的数据放在相对高速的部件上。

**不同之处**

* Cache主要解决**系统速度**问题，虚拟存储器为了解决**容量问题**
* Cache**全由硬件实现**，是硬件存储器，对所有程序员透明；虚拟存储器由**OS和硬件共同实现**，是逻辑上的存储器，对系统程序员不透明
* 虚拟存储器不命中时对系统性能的影响更大
* 辅存与CPU没有建立直接通路，需要经过主存访问





